{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a94022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec506c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_parquet(\"/Users/dankoh/warp-benchmark/src/data/dataset.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566638df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>constants</th>\n",
       "      <th>tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (not ( = cell_0_0 0)) (not ( = ce...</td>\n",
       "      <td>(declare-const cell_0_0 Int)</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in0 Int)\\n(declare-const in2 In...</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in6 Int)\\n(declare-const in5 In...</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and  ( &gt;=  n 1)  ( &lt;=  n 5))  ( ...</td>\n",
       "      <td>(declare-const n Int)</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in0 Int)\\n(declare-const in2 In...</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const c Int)\\n(declare-const w0 Int)\\...</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in0 Int)\\n(declare-const in2 In...</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in20 Int)\\n(declare-const in22 ...</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in20 Int)\\n(declare-const in22 ...</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const ch18 Int)\\n(declare-const ch19 ...</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Given the following examples of constraints fo...   \n",
       "1    Given the following examples of constraints fo...   \n",
       "2    Given the following examples of constraints fo...   \n",
       "3    Given the following examples of constraints fo...   \n",
       "4    Given the following examples of constraints fo...   \n",
       "..                                                 ...   \n",
       "666  Given the following examples of constraints fo...   \n",
       "667  Given the following examples of constraints fo...   \n",
       "668  Given the following examples of constraints fo...   \n",
       "669  Given the following examples of constraints fo...   \n",
       "670  Given the following examples of constraints fo...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    (assert (and (not ( = cell_0_0 0)) (not ( = ce...   \n",
       "1    (assert (and (and (and (and (and (and (and (an...   \n",
       "2    (assert (and (and (and (and (and (and (and (an...   \n",
       "3    (assert (and (and  ( >=  n 1)  ( <=  n 5))  ( ...   \n",
       "4    (assert (and (and (and (and (and (and (and (an...   \n",
       "..                                                 ...   \n",
       "666  (assert (and (and (and (and (and (and (and (an...   \n",
       "667  (assert (and (and (and (and (and (and (and (an...   \n",
       "668  (assert (and (and (and (and (and (and (and (an...   \n",
       "669  (assert (and (and (and (and (and (and (and (an...   \n",
       "670  (assert (and (and (and (and (and (and (and (an...   \n",
       "\n",
       "                                             constants   tier  \n",
       "0                         (declare-const cell_0_0 Int)  small  \n",
       "1    (declare-const in0 Int)\\n(declare-const in2 In...  small  \n",
       "2    (declare-const in6 Int)\\n(declare-const in5 In...  small  \n",
       "3                                (declare-const n Int)  small  \n",
       "4    (declare-const in0 Int)\\n(declare-const in2 In...  small  \n",
       "..                                                 ...    ...  \n",
       "666  (declare-const c Int)\\n(declare-const w0 Int)\\...  large  \n",
       "667  (declare-const in0 Int)\\n(declare-const in2 In...  large  \n",
       "668  (declare-const in20 Int)\\n(declare-const in22 ...  large  \n",
       "669  (declare-const in20 Int)\\n(declare-const in22 ...  large  \n",
       "670  (declare-const ch18 Int)\\n(declare-const ch19 ...  large  \n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ebe947",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = {}\n",
    "for problem in glob.glob(\"/Users/dankoh/warp-benchmark/src/spf-wca/custom/*\"):\n",
    "    problems[problem] = set()\n",
    "    for n in glob.glob(f\"{problem}/**/*.smt2\", recursive=True):\n",
    "        with open(n, \"r\") as f:\n",
    "            smt_lines = [line.strip() for line in f if line.strip()]\n",
    "            assertions = [line for line in smt_lines if line.startswith(\"(assert\")]\n",
    "            problems[problem].update(assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bed4289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"problem\"] = None\n",
    "for index, row in dataframe.iterrows():\n",
    "    matches = [problem.removeprefix(\"/Users/dankoh/warp-benchmark/src/spf-wca/custom/\") for problem in problems if row[\"answer\"] in problems[problem]]\n",
    "    if len(matches) != 1:\n",
    "        raise ValueError(f\"Ambiguous mapping for row {row['id']}: {matches}\")\n",
    "    dataframe.at[index, \"problem\"] = matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c818cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>constants</th>\n",
       "      <th>tier</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (not ( = cell_0_0 0)) (not ( = ce...</td>\n",
       "      <td>(declare-const cell_0_0 Int)</td>\n",
       "      <td>small</td>\n",
       "      <td>MazeSolver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in0 Int)\\n(declare-const in2 In...</td>\n",
       "      <td>small</td>\n",
       "      <td>BubbleSort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in6 Int)\\n(declare-const in5 In...</td>\n",
       "      <td>small</td>\n",
       "      <td>BinaryTreeSearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and  ( &gt;=  n 1)  ( &lt;=  n 5))  ( ...</td>\n",
       "      <td>(declare-const n Int)</td>\n",
       "      <td>small</td>\n",
       "      <td>TowerOfHanoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in0 Int)\\n(declare-const in2 In...</td>\n",
       "      <td>small</td>\n",
       "      <td>Collatz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const c Int)\\n(declare-const w0 Int)\\...</td>\n",
       "      <td>large</td>\n",
       "      <td>KnapsackSolver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in0 Int)\\n(declare-const in2 In...</td>\n",
       "      <td>large</td>\n",
       "      <td>DizzyRamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in20 Int)\\n(declare-const in22 ...</td>\n",
       "      <td>large</td>\n",
       "      <td>ComplexStateMachineParser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const in20 Int)\\n(declare-const in22 ...</td>\n",
       "      <td>large</td>\n",
       "      <td>BinarySearchTreeHeight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Given the following examples of constraints fo...</td>\n",
       "      <td>(assert (and (and (and (and (and (and (and (an...</td>\n",
       "      <td>(declare-const ch18 Int)\\n(declare-const ch19 ...</td>\n",
       "      <td>large</td>\n",
       "      <td>CaseFlipper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Given the following examples of constraints fo...   \n",
       "1    Given the following examples of constraints fo...   \n",
       "2    Given the following examples of constraints fo...   \n",
       "3    Given the following examples of constraints fo...   \n",
       "4    Given the following examples of constraints fo...   \n",
       "..                                                 ...   \n",
       "666  Given the following examples of constraints fo...   \n",
       "667  Given the following examples of constraints fo...   \n",
       "668  Given the following examples of constraints fo...   \n",
       "669  Given the following examples of constraints fo...   \n",
       "670  Given the following examples of constraints fo...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    (assert (and (not ( = cell_0_0 0)) (not ( = ce...   \n",
       "1    (assert (and (and (and (and (and (and (and (an...   \n",
       "2    (assert (and (and (and (and (and (and (and (an...   \n",
       "3    (assert (and (and  ( >=  n 1)  ( <=  n 5))  ( ...   \n",
       "4    (assert (and (and (and (and (and (and (and (an...   \n",
       "..                                                 ...   \n",
       "666  (assert (and (and (and (and (and (and (and (an...   \n",
       "667  (assert (and (and (and (and (and (and (and (an...   \n",
       "668  (assert (and (and (and (and (and (and (and (an...   \n",
       "669  (assert (and (and (and (and (and (and (and (an...   \n",
       "670  (assert (and (and (and (and (and (and (and (an...   \n",
       "\n",
       "                                             constants   tier  \\\n",
       "0                         (declare-const cell_0_0 Int)  small   \n",
       "1    (declare-const in0 Int)\\n(declare-const in2 In...  small   \n",
       "2    (declare-const in6 Int)\\n(declare-const in5 In...  small   \n",
       "3                                (declare-const n Int)  small   \n",
       "4    (declare-const in0 Int)\\n(declare-const in2 In...  small   \n",
       "..                                                 ...    ...   \n",
       "666  (declare-const c Int)\\n(declare-const w0 Int)\\...  large   \n",
       "667  (declare-const in0 Int)\\n(declare-const in2 In...  large   \n",
       "668  (declare-const in20 Int)\\n(declare-const in22 ...  large   \n",
       "669  (declare-const in20 Int)\\n(declare-const in22 ...  large   \n",
       "670  (declare-const ch18 Int)\\n(declare-const ch19 ...  large   \n",
       "\n",
       "                       problem  \n",
       "0                   MazeSolver  \n",
       "1                   BubbleSort  \n",
       "2             BinaryTreeSearch  \n",
       "3                 TowerOfHanoi  \n",
       "4                      Collatz  \n",
       "..                         ...  \n",
       "666             KnapsackSolver  \n",
       "667                  DizzyRamp  \n",
       "668  ComplexStateMachineParser  \n",
       "669     BinarySearchTreeHeight  \n",
       "670                CaseFlipper  \n",
       "\n",
       "[671 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdfe2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_models_by_problem(\n",
    "    output_dir=\"output\",\n",
    "    local_model_paths=[\".\", \"src\", \"archive\"],\n",
    "    openai_model_paths=[\"results\"],\n",
    "    problem_column=\"problem\",\n",
    "    problem_dataframe=None,  # Pass the dataframe with problem mappings\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze model performance by problem.\n",
    "    \n",
    "    Creates two files:\n",
    "    - output/local_model_problem_stats.json\n",
    "    - output/openai_model_problem_stats.json\n",
    "    \n",
    "    Each file contains counts of error types by model and problem.\n",
    "    \n",
    "    Args:\n",
    "        problem_dataframe: DataFrame containing id -> problem name mappings\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Constants (same as aggregate.py)\n",
    "    PARSE_ERROR = \"Parse error:\"\n",
    "    FORMAT_ERROR = \"Failed to extract <answer> from response.\"\n",
    "    FORMAT_ERROR_2 = \"Empty side\"\n",
    "    REASON_CORRECT = \"Constraints are logically equivalent.\"\n",
    "    REASON_SEMANTICS_A = \"Original does not imply generated.\"\n",
    "    REASON_SEMANTICS_B = \"Generated does not imply original.\"\n",
    "    REASON_SYNTAX = \"Could not parse results correctly.\"\n",
    "    REASON_FORMAT = \"Failed to extract response.\"\n",
    "    \n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[LOG] {msg}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Build ID to problem mapping if dataframe provided\n",
    "    id_to_problem = {}\n",
    "    if problem_dataframe is not None and problem_column in problem_dataframe.columns:\n",
    "        # Create mapping from ID to problem name\n",
    "        for idx, row in problem_dataframe.iterrows():\n",
    "            if not pd.isna(row[problem_column]):\n",
    "                id_to_problem[str(idx)] = row[problem_column]\n",
    "        \n",
    "        log(f\"Created mapping for {len(id_to_problem)} problem IDs to problem names\")\n",
    "    \n",
    "    # --- Helper functions ---\n",
    "    def find_local_stats_files():\n",
    "        all_files = []\n",
    "        for path in local_model_paths:\n",
    "            if os.path.exists(path):\n",
    "                found = list(Path(path).rglob(\"individual_stats.json\"))\n",
    "                all_files.extend(found)\n",
    "                log(f\"Found {len(found)} local stats files in {path}\")\n",
    "        return all_files\n",
    "    \n",
    "    def find_openai_result_files():\n",
    "        all_files = []\n",
    "        for path in openai_model_paths:\n",
    "            if os.path.exists(path):\n",
    "                for trial_dir in Path(path).glob(\"trial*\"):\n",
    "                    if trial_dir.is_dir():\n",
    "                        json_files = [f for f in trial_dir.glob(\"*.json\") if \"summary\" not in f.name]\n",
    "                        all_files.extend(json_files)\n",
    "                        log(f\"Found {len(json_files)} OpenAI result files in {trial_dir}\")\n",
    "        return all_files\n",
    "    \n",
    "    def extract_model_name(path, is_openai=False):\n",
    "        if is_openai:\n",
    "            filename = path.stem\n",
    "            if \"-20\" in filename:\n",
    "                model_name = filename.split(\"-20\")[0]\n",
    "                return model_name.rstrip(\"-\")\n",
    "            elif \"gpt\" in filename.lower() or \"claude\" in filename.lower():\n",
    "                parts = filename.split(\"-\")\n",
    "                if len(parts) > 1 and parts[1].isdigit() and len(parts[1]) == 4:\n",
    "                    return parts[0]\n",
    "                return filename\n",
    "            return filename\n",
    "        else:\n",
    "            parts = path.parts\n",
    "            for i, part in enumerate(parts):\n",
    "                if part.startswith(\"results_\") and i + 1 < len(parts):\n",
    "                    return parts[i + 1]\n",
    "            \n",
    "            indicators = [\"results_\", \"model_\", \"claude\", \"gpt\", \"llama\", \"gemini\"]\n",
    "            for part in parts:\n",
    "                for indicator in indicators:\n",
    "                    if indicator in part.lower():\n",
    "                        return part\n",
    "            \n",
    "            try:\n",
    "                return path.parent.parent.name\n",
    "            except:\n",
    "                return \"unknown_model\"\n",
    "    \n",
    "    def categorize_result(result):\n",
    "        \"\"\"Safely categorize a result dictionary\"\"\"\n",
    "        if not isinstance(result, dict):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        if result.get(\"result\") is True:\n",
    "            return \"correct\"\n",
    "        \n",
    "        reason = result.get(\"reason\", \"\")\n",
    "        if not isinstance(reason, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        if reason.startswith((FORMAT_ERROR, FORMAT_ERROR_2)) or reason == REASON_FORMAT:\n",
    "            return \"error_output_formatting\"\n",
    "        elif reason.startswith(PARSE_ERROR) or reason == REASON_SYNTAX:\n",
    "            return \"error_syntax\"\n",
    "        elif \"does not imply\" in reason or reason in (REASON_SEMANTICS_A, REASON_SEMANTICS_B):\n",
    "            return \"error_semantics\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "    \n",
    "    def get_problem_name(problem_id):\n",
    "        \"\"\"Get problem name from ID using the mapping\"\"\"\n",
    "        if problem_id is None:\n",
    "            return \"unknown\"\n",
    "        \n",
    "        problem_id_str = str(problem_id)\n",
    "        \n",
    "        # If we have a mapping, use it\n",
    "        if problem_id_str in id_to_problem:\n",
    "            return id_to_problem[problem_id_str]\n",
    "        \n",
    "        # Try integer index if possible\n",
    "        try:\n",
    "            idx = int(problem_id_str)\n",
    "            if str(idx) in id_to_problem:\n",
    "                return id_to_problem[str(idx)]\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "            \n",
    "        # No mapping found, return the ID\n",
    "        return problem_id_str\n",
    "    \n",
    "    # Initialize data structures for problem counts\n",
    "    local_models = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))  # model -> problem -> category -> count\n",
    "    openai_models = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))  # model -> problem -> category -> count\n",
    "    \n",
    "    # --- Process local model results ---\n",
    "    local_files = find_local_stats_files()\n",
    "    log(f\"Processing {len(local_files)} local model result files\")\n",
    "    \n",
    "    for file_path in local_files:\n",
    "        try:\n",
    "            with open(file_path) as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            model_name = extract_model_name(file_path)\n",
    "            log(f\"Processing {file_path} for model {model_name}\")\n",
    "            \n",
    "            # Handle the specific structure with \"small\", \"medium\", \"large\" categories\n",
    "            if isinstance(data, dict) and any(k in data for k in [\"small\", \"medium\", \"large\"]):\n",
    "                for difficulty, items in data.items():\n",
    "                    if isinstance(items, list):\n",
    "                        log(f\"Processing {len(items)} items in {difficulty} category\")\n",
    "                        for item in items:\n",
    "                            if not isinstance(item, dict):\n",
    "                                continue\n",
    "                                \n",
    "                            # Use the index field as problem_id\n",
    "                            problem_id = item.get(\"index\")\n",
    "                            if problem_id is None:\n",
    "                                continue\n",
    "                                \n",
    "                            # Get problem name using the mapping\n",
    "                            problem_name = get_problem_name(problem_id)\n",
    "                            \n",
    "                            # Get category and add to stats\n",
    "                            category = categorize_result(item)\n",
    "                            \n",
    "                            # Count this result for the model/problem\n",
    "                            local_models[model_name][problem_name][category] += 1\n",
    "                            local_models[model_name][problem_name][\"total_attempts\"] += 1\n",
    "            # Handle regular list format\n",
    "            elif isinstance(data, list):\n",
    "                log(f\"List format detected in {file_path}, length: {len(data)}\")\n",
    "                for item in data:\n",
    "                    # Skip non-dictionary items\n",
    "                    if not isinstance(item, dict):\n",
    "                        log(f\"Skipping non-dictionary item in list: {type(item)}\")\n",
    "                        continue\n",
    "                        \n",
    "                    # Extract problem identifier\n",
    "                    problem_id = None\n",
    "                    if problem_column in item:\n",
    "                        problem_id = item[problem_column]\n",
    "                    elif \"id\" in item:\n",
    "                        problem_id = item[\"id\"]\n",
    "                    elif \"index\" in item:\n",
    "                        problem_id = item[\"index\"]\n",
    "                    \n",
    "                    # Get problem name using the mapping\n",
    "                    problem_name = get_problem_name(problem_id)\n",
    "                    \n",
    "                    # Get category and add to stats\n",
    "                    category = categorize_result(item)\n",
    "                    \n",
    "                    # Count this result for the model/problem\n",
    "                    local_models[model_name][problem_name][category] += 1\n",
    "                    local_models[model_name][problem_name][\"total_attempts\"] += 1\n",
    "            # Handle regular dictionary format\n",
    "            elif isinstance(data, dict):\n",
    "                # Regular dictionary format\n",
    "                log(f\"Dictionary format detected in {file_path}, keys: {len(data)}\")\n",
    "                for problem_id, problem_data in data.items():\n",
    "                    # Skip non-dictionary items\n",
    "                    if not isinstance(problem_data, dict):\n",
    "                        log(f\"Skipping non-dictionary value for key {problem_id}: {type(problem_data)}\")\n",
    "                        continue\n",
    "                        \n",
    "                    # Extract problem identifier from the problem_data if possible\n",
    "                    if problem_column in problem_data:\n",
    "                        problem_id = problem_data[problem_column]\n",
    "                    elif \"id\" in problem_data:\n",
    "                        problem_id = problem_data[\"id\"]\n",
    "                    elif \"index\" in problem_data:\n",
    "                        problem_id = problem_data[\"index\"]\n",
    "                    \n",
    "                    # Get problem name using the mapping\n",
    "                    problem_name = get_problem_name(problem_id)\n",
    "                    \n",
    "                    # Get category and add to stats\n",
    "                    category = categorize_result(problem_data)\n",
    "                    \n",
    "                    # Count this result for the model/problem\n",
    "                    local_models[model_name][problem_name][category] += 1\n",
    "                    local_models[model_name][problem_name][\"total_attempts\"] += 1\n",
    "            else:\n",
    "                log(f\"Unrecognized data format in {file_path}: {type(data)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            log(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # --- Process OpenAI model results ---\n",
    "    openai_files = find_openai_result_files()\n",
    "    log(f\"Processing {len(openai_files)} OpenAI model result files\")\n",
    "    \n",
    "    for file_path in openai_files:\n",
    "        try:\n",
    "            with open(file_path) as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if \"results\" not in data:\n",
    "                log(f\"No results in {file_path}\")\n",
    "                continue\n",
    "                \n",
    "            model_name = extract_model_name(file_path, is_openai=True)\n",
    "            \n",
    "            for result in data[\"results\"]:\n",
    "                # Skip non-dictionary items\n",
    "                if not isinstance(result, dict):\n",
    "                    log(f\"Skipping non-dictionary result in OpenAI file: {type(result)}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Extract problem identifier\n",
    "                problem_id = None\n",
    "                if \"custom_id\" in result:\n",
    "                    problem_id = result[\"custom_id\"]\n",
    "                elif problem_column in result:\n",
    "                    problem_id = result[problem_column]\n",
    "                elif \"index\" in result:\n",
    "                    problem_id = result[\"index\"]\n",
    "                \n",
    "                # Get problem name using the mapping\n",
    "                problem_name = get_problem_name(problem_id)\n",
    "                \n",
    "                # Get category\n",
    "                category = categorize_result(result)\n",
    "                \n",
    "                # Count this result for the model/problem\n",
    "                openai_models[model_name][problem_name][category] += 1\n",
    "                openai_models[model_name][problem_name][\"total_attempts\"] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            log(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Write output files\n",
    "    with open(f\"{output_dir}/local_model_problem_stats.json\", \"w\") as f:\n",
    "        json.dump(local_models, f, indent=2)\n",
    "    \n",
    "    with open(f\"{output_dir}/openai_model_problem_stats.json\", \"w\") as f:\n",
    "        json.dump(openai_models, f, indent=2)\n",
    "    \n",
    "    # Create per-problem reports\n",
    "    problem_dir = Path(output_dir) / \"problems\"\n",
    "    problem_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Collect all problems seen\n",
    "    all_problems = set()\n",
    "    for model_data in local_models.values():\n",
    "        all_problems.update(model_data.keys())\n",
    "    for model_data in openai_models.values():\n",
    "        all_problems.update(model_data.keys())\n",
    "    \n",
    "    # Create per-problem reports\n",
    "    for problem in all_problems:\n",
    "        if problem == \"unknown\":\n",
    "            continue\n",
    "            \n",
    "        problem_report = {\n",
    "            \"problem\": problem,\n",
    "            \"local_models\": {},\n",
    "            \"openai_models\": {}\n",
    "        }\n",
    "        \n",
    "        # Add local model data\n",
    "        for model, problems in local_models.items():\n",
    "            if problem in problems:\n",
    "                problem_report[\"local_models\"][model] = problems[problem]\n",
    "                \n",
    "        # Add OpenAI model data\n",
    "        for model, problems in openai_models.items():\n",
    "            if problem in problems:\n",
    "                problem_report[\"openai_models\"][model] = problems[problem]\n",
    "        \n",
    "        # Write problem report\n",
    "        safe_name = problem.replace(\"/\", \"_\").replace(\":\", \"-\")\n",
    "        with open(f\"{problem_dir}/{safe_name}.json\", \"w\") as f:\n",
    "            json.dump(problem_report, f, indent=2)\n",
    "    \n",
    "    print(f\"Analysis complete. Reports written to:\")\n",
    "    print(f\"- {output_dir}/local_model_problem_stats.json\")\n",
    "    print(f\"- {output_dir}/openai_model_problem_stats.json\")\n",
    "    print(f\"- {output_dir}/problems/ (per-problem reports)\")\n",
    "    \n",
    "    return {\n",
    "        \"local_models\": dict(local_models),\n",
    "        \"openai_models\": dict(openai_models)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e86062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Created mapping for 671 problem IDs to problem names\n",
      "[LOG] Found 27 local stats files in .\n",
      "[LOG] Found 27 local stats files in src\n",
      "[LOG] Processing 54 local model result files\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/2025-05-07_10-37-40/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-7B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/2025-05-06_17-50-14/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-7B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/2025-05-06_17-23-57/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-7B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/2025-05-06_13-51-13/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-14B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/2025-05-06_14-34-41/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-14B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/2025-05-06_13-00-39/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-14B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-32B/2025-05-05_21-51-34/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-32B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-32B/2025-05-05_23-00-36/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-32B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-32B/2025-05-06_00-09-25/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-32B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_dannkoh/warp-1.0/2025-05-05_20-25-50/stats/individual_stats.json for model warp-1.0\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_dannkoh/warp-1.0/2025-05-05_20-46-32/stats/individual_stats.json for model warp-1.0\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_dannkoh/warp-1.0/2025-05-05_20-36-32/stats/individual_stats.json for model warp-1.0\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-7B-Instruct/2025-05-07_10-17-41/stats/individual_stats.json for model Qwen2.5-7B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-7B-Instruct/2025-05-07_09-57-10/stats/individual_stats.json for model Qwen2.5-7B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-7B-Instruct/2025-05-07_09-42-51/stats/individual_stats.json for model Qwen2.5-7B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-3B-Instruct/2025-05-06_04-32-43/stats/individual_stats.json for model Qwen2.5-3B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-3B-Instruct/2025-05-06_04-54-10/stats/individual_stats.json for model Qwen2.5-3B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-3B-Instruct/2025-05-06_04-43-30/stats/individual_stats.json for model Qwen2.5-3B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-14B-Instruct/2025-05-06_16-44-03/stats/individual_stats.json for model Qwen2.5-14B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-14B-Instruct/2025-05-06_16-01-51/stats/individual_stats.json for model Qwen2.5-14B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-14B-Instruct/2025-05-06_18-39-51/stats/individual_stats.json for model Qwen2.5-14B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-32B-Instruct/2025-05-06_02-36-44/stats/individual_stats.json for model Qwen2.5-32B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-32B-Instruct/2025-05-06_01-58-01/stats/individual_stats.json for model Qwen2.5-32B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-32B-Instruct/2025-05-06_01-19-08/stats/individual_stats.json for model Qwen2.5-32B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_tiiuae/Falcon3-10B-Instruct/2025-05-06_03-41-06/stats/individual_stats.json for model Falcon3-10B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_tiiuae/Falcon3-10B-Instruct/2025-05-06_03-16-08/stats/individual_stats.json for model Falcon3-10B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_tiiuae/Falcon3-10B-Instruct/2025-05-06_04-05-57/stats/individual_stats.json for model Falcon3-10B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/2025-05-07_10-37-40/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-7B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/2025-05-06_17-50-14/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-7B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/2025-05-06_17-23-57/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-7B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/2025-05-06_13-51-13/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-14B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/2025-05-06_14-34-41/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-14B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/2025-05-06_13-00-39/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-14B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-32B/2025-05-05_21-51-34/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-32B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-32B/2025-05-05_23-00-36/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-32B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_deepseek-ai/DeepSeek-R1-Distill-Qwen-32B/2025-05-06_00-09-25/stats/individual_stats.json for model DeepSeek-R1-Distill-Qwen-32B\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_dannkoh/warp-1.0/2025-05-05_20-25-50/stats/individual_stats.json for model warp-1.0\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_dannkoh/warp-1.0/2025-05-05_20-46-32/stats/individual_stats.json for model warp-1.0\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_dannkoh/warp-1.0/2025-05-05_20-36-32/stats/individual_stats.json for model warp-1.0\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-7B-Instruct/2025-05-07_10-17-41/stats/individual_stats.json for model Qwen2.5-7B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-7B-Instruct/2025-05-07_09-57-10/stats/individual_stats.json for model Qwen2.5-7B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-7B-Instruct/2025-05-07_09-42-51/stats/individual_stats.json for model Qwen2.5-7B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-3B-Instruct/2025-05-06_04-32-43/stats/individual_stats.json for model Qwen2.5-3B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-3B-Instruct/2025-05-06_04-54-10/stats/individual_stats.json for model Qwen2.5-3B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-3B-Instruct/2025-05-06_04-43-30/stats/individual_stats.json for model Qwen2.5-3B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-14B-Instruct/2025-05-06_16-44-03/stats/individual_stats.json for model Qwen2.5-14B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-14B-Instruct/2025-05-06_16-01-51/stats/individual_stats.json for model Qwen2.5-14B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-14B-Instruct/2025-05-06_18-39-51/stats/individual_stats.json for model Qwen2.5-14B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-32B-Instruct/2025-05-06_02-36-44/stats/individual_stats.json for model Qwen2.5-32B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-32B-Instruct/2025-05-06_01-58-01/stats/individual_stats.json for model Qwen2.5-32B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_Qwen/Qwen2.5-32B-Instruct/2025-05-06_01-19-08/stats/individual_stats.json for model Qwen2.5-32B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_tiiuae/Falcon3-10B-Instruct/2025-05-06_03-41-06/stats/individual_stats.json for model Falcon3-10B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_tiiuae/Falcon3-10B-Instruct/2025-05-06_03-16-08/stats/individual_stats.json for model Falcon3-10B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Processing src/results_tiiuae/Falcon3-10B-Instruct/2025-05-06_04-05-57/stats/individual_stats.json for model Falcon3-10B-Instruct\n",
      "[LOG] Processing 333 items in small category\n",
      "[LOG] Processing 333 items in medium category\n",
      "[LOG] Processing 5 items in large category\n",
      "[LOG] Found 4 OpenAI result files in results/trial1\n",
      "[LOG] Found 4 OpenAI result files in results/trial3\n",
      "[LOG] Found 4 OpenAI result files in results/trial2\n",
      "[LOG] Processing 12 OpenAI model result files\n",
      "Analysis complete. Reports written to:\n",
      "- output/local_model_problem_stats.json\n",
      "- output/openai_model_problem_stats.json\n",
      "- output/problems/ (per-problem reports)\n"
     ]
    }
   ],
   "source": [
    "# Update the function call to pass the dataframe with problem mappings\n",
    "results = analyze_models_by_problem(\n",
    "    problem_dataframe=dataframe,  # Pass the dataframe with problem mappings\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
